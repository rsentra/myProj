{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "\n",
    "#리스트합침\n",
    "def ex(dat,col): \n",
    "    result=[]\n",
    "    for x in dat:\n",
    "        result.append(x[col])\n",
    "    return str(result)\n",
    "\n",
    "# path 지우기\n",
    "def del_path(str):\n",
    "    return str.replace(\"$$[BAT_DATA_HOME]/\",\"\").replace(\"'\",\"\")\n",
    "\n",
    "# 파일에 대한 컬럼정보 추출\n",
    "def get_columns(blocks,fType):\n",
    "    cols=['block_id','raw_file_nm','cond','calc_expression','col_id','desc','nm']\n",
    "    df_file = pd.DataFrame(columns=cols)\n",
    "    for block in data['blocks']:\n",
    "        if len(block[fType])!=0:\n",
    "            for inp in block[fType]:\n",
    "                if (isinstance(inp,dict)) & ('ffd' in inp.keys()):\n",
    "                    lst=[]\n",
    "                    for col in inp['ffd']['columns']:\n",
    "                        lst=[block['block_id'],del_path(inp['raw_file_nm']),inp['cond']]\n",
    "                        lst.append(' ' + str(col['calc_expression']))\n",
    "                        lst.append(col['col_id'])\n",
    "                        lst.append(col['desc'])\n",
    "                        lst.append(col['nm'])\n",
    "                        dd=pd.DataFrame(lst).T\n",
    "                        dd.columns=cols\n",
    "                        df_file=df_file.append(dd)\n",
    "    return df_file\n",
    "\n",
    "\n",
    "#query 추출\n",
    "def get_query(qry):\n",
    "    cols=['block_id','sql']\n",
    "    df_qry = pd.DataFrame(columns=cols)\n",
    "    for block in data['blocks']:\n",
    "        if 'query' in block.keys():\n",
    "            if len(block['query'])!=0:\n",
    "                qry=block['query']\n",
    "                lst=qry.split(\"\\n\")\n",
    "                dd=pd.DataFrame(lst, columns=['sql'])\n",
    "                dd['block_id']=block['block_id']\n",
    "                df_qry=df_qry.append(dd[cols])\n",
    "    return df_qry\n",
    "\n",
    "#공백제거\n",
    "def get_strings(st):\n",
    "    strings=str(st).strip()\n",
    "    if strings.upper().startswith('SELECT'):\n",
    "        return strings\n",
    "    elif strings.upper().startswith('FROM'):\n",
    "        return strings\n",
    "    else:\n",
    "        strings=\"    \"+ strings\n",
    "        return strings\n",
    "    \n",
    "# file 유무 체크 및 path, json data return\n",
    "def fileCheck(row):\n",
    "    res=None\n",
    "    json_path=row['Path']\n",
    "    json_file=row['FileName']\n",
    "    js= os.path.join(json_path,json_file)\n",
    "    if not os.path.isfile(js):\n",
    "        return 'file notfnd -> ' + js,'er'\n",
    "    json_data=open(js, encoding='UTF8')\n",
    "    data = json.load(json_data)\n",
    "    if data==None: \n",
    "        return 'file read error','er'\n",
    "    return None,js,data\n",
    "\n",
    "#json -> excel\n",
    "def procData(json_file,data):\n",
    "    try:  \n",
    "        df = pd.DataFrame()\n",
    "        # for block in data['blocks']:\n",
    "        #     df=df.append(block,ignore_index=True)\n",
    "        df=pd.json_normalize(data['blocks'])\n",
    "\n",
    "        df['input_cnt']=df.inputs.apply(lambda x: len(x))\n",
    "        df['output_cnt']=df.outputs.apply(lambda x: len(x))\n",
    "\n",
    "        df['input_files']=df.inputs.apply(lambda x: ex(x,'raw_file_nm'))\n",
    "        df['output_files']=df.outputs.apply(lambda x: ex(x,'raw_file_nm'))\n",
    "        df['input_files']=df['input_files'].apply(lambda x: del_path(x))\n",
    "        df['output_files']=df['output_files'].apply(lambda x: del_path(x))\n",
    "        if 'outfile1' in df.columns: \n",
    "            df['outfile1']=df['outfile1'].apply(lambda x: del_path(str(x))).replace('nan',\"\")\n",
    "        # df=df.applymap(lambda x: str(x).replace(\"$$[BAT_DATA_HOME]/ccr/\",\"\").replace(\"'\",\"\"))\n",
    "        df.drop(columns=['inputs','outputs'],inplace=True)\n",
    "\n",
    "        #in,out col추출\n",
    "        df_inFile=h=get_columns(data,\"inputs\")\n",
    "        df_outFile=h=get_columns(data,\"outputs\")\n",
    "        df_query= get_query(data)\n",
    "        df_query['sql']=df_query['sql'].apply(lambda x: get_strings(x))\n",
    "        #sql제거\n",
    "        merge_cnt=0\n",
    "        if 'query' in df.columns:\n",
    "            df['query']=df['query'].fillna('')\n",
    "            df['merge_yn']=df['query'].str.contains('merge',case=False)  #query문에 merge 사용수\n",
    "            df['query']= df['query'].apply(lambda x: 'sql있음' if len(str(x))>10 else  '')\n",
    "        df_query['merge_cnt'] = merge_cnt\n",
    "        \n",
    "        wrt_file=json_file+'.xlsx'\n",
    "        with pd.ExcelWriter(wrt_file) as writer:  \n",
    "              df.to_excel(writer, sheet_name='json',index=True),\n",
    "              df_inFile.to_excel(writer, sheet_name='input',index=False),\n",
    "              df_outFile.to_excel(writer, sheet_name='output',index=False),\n",
    "              df_query.to_excel(writer, sheet_name='query',index=False)\n",
    "        return None,df\n",
    "\n",
    "    except:\n",
    "        print('fail ',  '- ', json_file)\n",
    "        logging.info(f'fail to process {json_file}')\n",
    "        return 'fail ' +  '- '+ json_file\n",
    "\n",
    "    \n",
    "#요약리스트 생성\n",
    "def makeList(json_file,df):\n",
    "    df_list=pd.DataFrame()\n",
    "    df_list['block_id']=df['block_id']\n",
    "    df_list['job']=json_file\n",
    "    if 'query' in df.columns:\n",
    "        df_list['query']=df['query']\n",
    "    else: df_list['query']=\"\"\n",
    "    df_list['merge_yn']=df['merge_yn']\n",
    "    if 'cmd' in df.columns:\n",
    "        df_list['cmd']=df['cmd']\n",
    "    else:\n",
    "        df_list['cmd']=\"\"\n",
    "    df_list['nm']=df['nm']\n",
    "    return df_list\n",
    "#-------------------------------------------------------------\n",
    "\n",
    "logging.basicConfig(filename='jobs.log', level=logging.DEBUG)\n",
    "logging.info('Started : %s'%time.strftime(\"%Y%m%d %H:%M:%S\",time.localtime()))\n",
    "\n",
    "df_ListAll=pd.DataFrame()\n",
    "control=pd.read_excel('jobs_계약.xlsx',sheet_name='control',header=0)        \n",
    "try:\n",
    "    \n",
    "    for seq, row in control.iterrows():\n",
    "        if str(row['Action']).upper()=='Y':\n",
    "            result = fileCheck(row)\n",
    "            if result[0]!=None:\n",
    "                raise Exception(result)\n",
    "                \n",
    "            json_file=result[1]\n",
    "            data=result[2]\n",
    "            \n",
    "            res = procData(json_file,data)\n",
    "            if res[0]==None:\n",
    "                dd = makeList(row['FileName'],res[1])\n",
    "                df_ListAll=pd.concat([df_ListAll,dd])\n",
    "                wrt_file='listAll.xlsx'\n",
    "                with pd.ExcelWriter(wrt_file) as writer:  \n",
    "                    df_ListAll.to_excel(writer, sheet_name='jobList',index=True)\n",
    "            else:\n",
    "                raise Exception(res[0])\n",
    "            print(\"succ - \",json_file)\n",
    "     \n",
    "    print(\"job completed~~\")\n",
    "except  Exception as e: \n",
    "        print(f'error occured..{str(e)}')\n",
    "        logging.info('%s ← error occured at..%s' %(str(e),time.strftime(\"%Y%m%d %H:%M:%S\",time.localtime())))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##끝  아래는 디버깅용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrt_file='list.xlsx'\n",
    "with pd.ExcelWriter(wrt_file) as writer:  \n",
    "              df_ListAll.to_excel(writer, sheet_name='json',index=True)\n",
    "# df_ListAll.loc[df_ListAll['job'].isin(['TSP-btCcrM862_8607.json']),['job','cmd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "## 디버깅을 위한 로직\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "# 파일에 대한 컬럼정보 추출\n",
    "def get_columns(blocks,fType):\n",
    "    cols=['block_id','raw_file_nm','col_id','nm','desc','calc_expression']\n",
    "    # 각 블럭내 inputs정보 \n",
    "    df_file = pd.DataFrame(columns=cols)\n",
    "    for block in data['blocks']:\n",
    "        if len(block[fType])!=0:\n",
    "            for temp in block[fType]:\n",
    "                for inp in temp:\n",
    "                    if str(type(inp))==\"<class 'dict'>\":\n",
    "                        for col in inp['ffd']['columns']:\n",
    "                            lst= [block['block_id'],del_path(inp['raw_file_nm']),col['col_id'],col['nm'],col['desc'],col['calc_expression']]\n",
    "                            dd=pd.DataFrame(lst).T\n",
    "                            dd.columns=cols\n",
    "                            df_file=df_file.append(dd)\n",
    "\n",
    "    return df_file\n",
    "\n",
    "def get_columns2(blocks,fType):\n",
    "    cols=['block_id','raw_file_nm','cond','calc_expression','col_id','desc','nm']\n",
    "    # 각 블럭내 inputs정보 \n",
    "    df_file = pd.DataFrame(columns=cols)\n",
    "  \n",
    "    for block in data['blocks']:\n",
    "        if len(block[fType])!=0:\n",
    "            for inp in block[fType]:\n",
    "                if (isinstance(inp,dict)) & ('ffd' in inp.keys()):\n",
    "                    lst=[]\n",
    "                    for col in inp['ffd']['columns']:\n",
    "                        lst=[block['block_id'],del_path(inp['raw_file_nm']),inp['cond']]\n",
    "                        lst.append(' ' + str(col['calc_expression']))\n",
    "                        lst.append(col['col_id'])\n",
    "                        lst.append(col['desc'])\n",
    "                        lst.append(col['nm'])\n",
    "                      #    print(col['calc_expression'])\n",
    "                        dd=pd.DataFrame(lst).T\n",
    "                        dd.columns=cols\n",
    "                        df_file=df_file.append(dd)\n",
    "    return df_file\n",
    "\n",
    "json_path='D:/kpayins/02.참조모델/03 배치/KKO_tera_20200708/'\n",
    "# json_path='k:/7000. 팀별공유자료/7200. 업무개발/7220. 자동차보험/04.배치\\KKO_tera_20200708/KKO_tera_20200708/ccm/'\n",
    "# json_file='TSP-btCcrM862_8607.json'\n",
    "json_file='TSP-btCcrJ301_7807.json'\n",
    "# json_file='TSP-btCcrM420_7582.json'\n",
    "# json_file=\"TSP-btCcrM307_1561.json\"\n",
    "json_file=\"TSP-btCcrA370_8428.json\"\n",
    "json_file=\"TSP-btCcrH301_320.json\"\n",
    "\n",
    "json_data=open(json_path+json_file, encoding='UTF8')\n",
    "data = json.load(json_data)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df_list=pd.DataFrame()\n",
    "# for block in data['blocks']:\n",
    "#     df=df.append(block,ignore_index=True)\n",
    "df=pd.json_normalize(data['blocks'])\n",
    "\n",
    "df['input_cnt']=df.inputs.apply(lambda x: len(x))\n",
    "df['output_cnt']=df.outputs.apply(lambda x: len(x))\n",
    "\n",
    "df['input_files']=df.inputs.apply(lambda x: ex(x,'raw_file_nm'))\n",
    "df['output_files']=df.outputs.apply(lambda x: ex(x,'raw_file_nm'))\n",
    "df['input_files']=df['input_files'].apply(lambda x: del_path(x))\n",
    "df['output_files']=df['output_files'].apply(lambda x: del_path(x))\n",
    "if 'outfile1' in df.columns: \n",
    "    df['outfile1']=df['outfile1'].apply(lambda x: del_path(str(x))).replace('nan',\"\")\n",
    "# df=df.applymap(lambda x: str(x).replace(\"$$[BAT_DATA_HOME]/ccr/\",\"\").replace(\"'\",\"\"))\n",
    "df.drop(columns=['inputs','outputs'],inplace=True)\n",
    "\n",
    "#in,out col추출\n",
    "df_inFile=h=get_columns2(data,\"inputs\")\n",
    "df_outFile=h=get_columns2(data,\"outputs\")\n",
    "df_query= get_query(data)\n",
    "df_query['sql']=df_query['sql'].apply(lambda x: get_strings(x))\n",
    "merge_cnt = 0\n",
    "\n",
    "df['merge_cnt']=0\n",
    "if 'query' in df.columns:\n",
    "    df['query']=df['query'].fillna('')\n",
    "#     exp=\"query.str.contains('merge',case=False)\"\n",
    "#     df['merge_cnt'] =df.query(exp,engine=\"python\")\n",
    "    df['merge_yn']=df['query'].str.contains('merge',case=False)\n",
    "    df['query']= df['query'].apply(lambda x: 'sql있음' if len(str(x))>10 else  '')\n",
    "    \n",
    "#요약리스트 생성\n",
    "df_list['block_id']=df['block_id']\n",
    "df_list['job']=json_file\n",
    "if 'query' in df.columns:\n",
    "    df_list['query']=df['query'] \n",
    "else: df_list['query']=\"\"\n",
    "df_list['merge_yn']=df['merge_yn']\n",
    "if 'cmd' in df.columns:\n",
    "    df_list['cmd']=df['cmd']\n",
    "else:\n",
    "    df_list['cmd']=\"\"\n",
    "df_list['nm']=df['nm']\n",
    "#---------------\n",
    "\n",
    "wrt_path='d:/kpayins/02.참조모델/03 배치/'\n",
    "wrt_file=json_file+'.xlsx'\n",
    "with pd.ExcelWriter(wrt_path+wrt_file) as writer:  \n",
    "      df.to_excel(writer, sheet_name='json',index=True),\n",
    "      df_inFile.to_excel(writer, sheet_name='input',index=False),\n",
    "      df_outFile.to_excel(writer, sheet_name='output',index=False),\n",
    "      df_query.to_excel(writer, sheet_name='query',index=False)  \n",
    "\n",
    "wrt_file='listAll.xlsx'\n",
    "with pd.ExcelWriter(wrt_path+wrt_file) as writer:  \n",
    "      df_list.to_excel(writer, sheet_name='jobList',index=True)    \n",
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1     False\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "5     False\n",
       "6     False\n",
       "7     False\n",
       "8     False\n",
       "9      True\n",
       "10    False\n",
       "11    False\n",
       "12    False\n",
       "13    False\n",
       "14    False\n",
       "15    False\n",
       "16    False\n",
       "17    False\n",
       "Name: nm, dtype: bool"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp=\"nm.str.upper().contains('자동차')\"\n",
    "# df.query(exp,engine=\"python\")\n",
    "df['nm'].str.contains('자동차',case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"name\": [\"White tiger\", \"Tiger black\", \"Red tiger\"], \"age\": [5, 7, 9]}\n",
    "df = pd.DataFrame(data)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str_expr = \"name.str.contains('tiger')\" # 문자열에 tiger 포함\n",
    "# df_q = df.query(str_expr,engine='python')               # 조건 부합 데이터 추출\n",
    "df_q\n",
    "# display_side_by_side(df, df_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "a=[1,2]\n",
    "b={\"a\":1,\"c\":2}\n",
    "# if type(a)==types.IntType:\n",
    "#     print(1)\n",
    "isinstance(b, dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # len(data['blocks'][2]['outputs'])\n",
    "inp=data['blocks'][2]\n",
    "print(type(inp))\n",
    "# if str(type(inp))==\"<class 'dict'>\":\n",
    "#      for col in inp['ffd']['columns']:\n",
    "#          lst= [block['block_id'],del_path(inp['raw_file_nm']),col['col_id'],col['nm'],col['desc'],col['calc_expression']]\n",
    "\n",
    "# # temp=data['blocks'][2]['inputs']\n",
    "# # for inp in temp:\n",
    "#     print(inp['ffd'])\n",
    "if 'cmd' in inp.keys():\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['block_id','raw_file_nm','col_id','nm','desc','calc_expression']\n",
    "    # 각 블럭내 inputs정보 \n",
    "fType='inputs'\n",
    "df_file = pd.DataFrame(columns=cols)\n",
    "for block in data['blocks']:\n",
    "        if len(block[fType])!=0:\n",
    "            print(type(block[fType]))\n",
    "            for temp in block[fType]:\n",
    "                for inp in temp:\n",
    "                    if str(type(inp))==\"<class 'dict'>\":\n",
    "                        for col in inp['ffd']['columns']:\n",
    "                            lst= [block['block_id'],del_path(inp['raw_file_nm']),col['col_id'],col['nm'],col['desc'],col['calc_expression']]\n",
    "                            dd=pd.DataFrame(lst).T\n",
    "                            dd.columns=cols\n",
    "                            df_file=df_file.append(dd)\n",
    "#                     else: print(inp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for root,dirs,files in os.walk('d:/'):\n",
    "    for fname in files:\n",
    "        full_name=os.path.join(root,fname)\n",
    "        print(full_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cols_proc(col):\n",
    "    if col['calc_expression']==None:\n",
    "        col['calc_expression']=\"\"\n",
    "    return col['col_id'] +','+col['nm'] +','+ col['desc'] +','+ col['calc_expression']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## json구조\n",
    "json -> {[blocks],desc11,grp_nm,name} -> [{inputs}] -> \n",
    "  {cond,ffd{columns,desc,ffd_id,nm},ffd_id,raw_file_nm,role_type_cd,sequence} \n",
    "\n",
    "data['blocks'][0]['inputs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict구조 컬럼을 나눔, inputs,outputs\n",
    "df1 = pd.concat((pd.DataFrame([x for x in df.inputs])),\n",
    "        (pd.DataFrame([x for x in df.outputs]))], axis=1, keys=['blk','inp','oup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame()\n",
    "for d in df.inputs: #리스트\n",
    "    for x in d:   #dict:cond,ffd,ffd_id,raw_file_nm,role_type_cd,sequence\n",
    "                  ## dict->ffd  \n",
    "        #         print(pd.DataFrame(x))\n",
    "        dt=pd.DataFrame(x)\n",
    "        print(dt.columns)\n",
    "#         df1.append(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모든 컬럼이 dict구조인 경우\n",
    "dfs = [pd.DataFrame([x for x in df[col]]) for col in df.columns]\n",
    "df1 = pd.concat(dfs, axis=1, keys=df.columns)\n",
    "with pd.ExcelWriter('d:/kpayins/json.xlsx') as writer:  \n",
    "    df1.to_excel(writer, sheet_name='json',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for block in data['blocks']:\n",
    "#     print('------------------------')\n",
    "    print(block['block_id'],block['depend_on'],block['nm'])\n",
    "    if len(block['inputs'])>1:\n",
    "        print('inp = ', len(block['inputs']))\n",
    "        for inp in block['inputs']:\n",
    "            for k,v in inp.items():\n",
    "                if len(v)>0:\n",
    "                    if k=='raw_file_nm':\n",
    "                        print(v) \n",
    "    if len(block['outputs'])>1:\n",
    "        print('out = ', len(block['outputs']))\n",
    "        for out in block['outputs']:\n",
    "            for k,v in out.items():\n",
    "                if len(v)>0:\n",
    "                    if k=='raw_file_nm':\n",
    "                        print(v) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyLi=['block_id','cmd', 'depend_on', 'inputs', 'join_cond', 'join_type', 'key_map', 'nm', 'outputs', 'type']\n",
    "outLi=['block_id','depend_on','nm','type', 'key_map','input_cnt','output_cnt','input_files','output_files','inputs','outputs']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
